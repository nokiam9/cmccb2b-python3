version: '2'

services:
  nginx:
    build:
      context: nginx/
    image: cmccb2b/nginx
    container_name: nginx
    restart: always

    networks:
      - cmccb2b_net
    ports:
      - "80:80"
      - "6800:6800"
      - "9000:9000"
      - "443:443"

  scrapy:
    build:
      context: scrapy/
    image: cmccb2b/scrapy
    container_name: scrapy
    restart: always

    networks:
      - cmccb2b_net

    volumes:
      - download_volume:/download

  flask:
    build:
      context: flask/
    image: cmccb2b/flask
    container_name: flask
    restart: always

    networks:
      - cmccb2b_net

    volumes:
      - download_volume:/download

    environment:
      - FLASK_APP=app/main.py
      - FLASK_DEBUG=1
      - 'RUN=flask run --host=0.0.0.0 --port=80'

  crontab:
    build:
      context: crontab/
    image: cmccb2b/crontab
    container_name: crontab
    restart: always

    networks:
      - cmccb2b_net

    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro

  xunsearch-server:
    build:
      context: xunsearch/
      dockerfile: xunsearch-server.dockerfile
    image: cmccb2b/xunsearch-server
    container_name: xunsearch-server
    restart: always

    networks:
      - cmccb2b_net

    volumes:
      - ../data/xunsearch:/usr/local/xunsearch/data

  xunsearch:
    build:
      context: xunsearch/
      dockerfile: xunsearch.dockerfile
    image: cmccb2b/xunsearch
    container_name: xunsearch
    restart: always

    networks:
      - cmccb2b_net


networks:
  cmccb2b_net:
    external: true


volumes:
  download_volume:      # Public volume for Scrapy & Flask where store downloaded files & images
